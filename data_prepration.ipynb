{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import fftpack\n",
    "from scipy import ndimage\n",
    "from sklearn import svm, metrics\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import imageio\n",
    "import matplotlib.image as mpimage\n",
    "import cv2\n",
    "import glob\n",
    "import h5py\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "import datetime as dt\n",
    "from six.moves import range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path=\"/home/csed/ELC_activity/train\"\n",
    "test_path=\"/home/csed/ELC_activity/test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ada', 'haha', 'idi', 'sasa', 'uda']\n"
     ]
    }
   ],
   "source": [
    "pixel_depth=255.0\n",
    "train_labels=os.listdir(train_path)\n",
    "test_labels=os.listdir(test_path)\n",
    "train_labels.sort()\n",
    "test_labels.sort()\n",
    "print(train_labels)\n",
    "nb_classes= 5\n",
    "global_features_train=[]\n",
    "train_classes=[]\n",
    "test_classes=[]\n",
    "\n",
    "\n",
    "i,j=0,0\n",
    "k=0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/csed/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:7: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0.\n",
      "Use ``matplotlib.pyplot.imread`` instead.\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[status] processed folder: ada\n",
      "[status] processed folder: haha\n",
      "[status] processed folder: idi\n",
      "[status] processed folder: sasa\n",
      "[status] processed folder: uda\n",
      "[status] completed global feature extraction..\n",
      "[status] feature vector size (493, 32, 32)\n",
      "[status] training labels (493,)\n"
     ]
    }
   ],
   "source": [
    "for training_name in train_labels:\n",
    "    path=os.path.join(train_path,training_name,'*')\n",
    "    files=glob.glob(path)\n",
    "    current_label=training_name\n",
    "    k=1\n",
    "    for fl in files:\n",
    "        image=(ndimage.imread(fl).astype(float)-pixel_depth/2)/pixel_depth\n",
    "        global_feature=np.hstack([image])\n",
    "        train_classes.append(current_label)\n",
    "        global_features_train.append(global_feature)\n",
    "\n",
    "        i+=1\n",
    "        k+1\n",
    "    print(\"[status] processed folder: {}\".format(current_label))\n",
    "    j+=1\n",
    "print(\"[status] completed global feature extraction..\")\n",
    "print(\"[status] feature vector size {}\".format(np.array(global_features_train).shape))\n",
    "print(\"[status] training labels {}\".format(np.array(train_classes).shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[status] training labels encoded...\n"
     ]
    }
   ],
   "source": [
    "#labels = (np.arange(nb_classes) == labels[:,None]).astype(np.float32)\n",
    "targetNames=np.unique(train_classes)\n",
    "le=LabelEncoder()\n",
    "target=le.fit_transform(train_classes)\n",
    "print(\"[status] training labels encoded...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples, nx, ny=np.array(global_features_train).shape\n",
    "d2_global_features=np.array(global_features_train).reshape((n_samples, nx*ny))\n",
    "#scaler=MinMaxScaler(feature_range=(0,1))\n",
    "#rescaled_features=scaler.fit_transform(d2_global_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Status] feature vector normalized...\n",
      "[Status] target label[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
      " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
      " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
      " 4 4 4 4 4 4 4 4 4 4 4 4]\n",
      "[Status] target label shape (493,)\n"
     ]
    }
   ],
   "source": [
    "print(\"[Status] feature vector normalized...\")\n",
    "\n",
    "print(\"[Status] target label{}\".format(target))\n",
    "print(\"[Status] target label shape {}\".format(target.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<HDF5 dataset \"dataset_1\": shape (493,), type \"<i8\">"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h5f_data=h5py.File('/home/csed/ELC_activity/output_train_svm/data.h5','w')\n",
    "h5f_data.create_dataset('dataset_1',data=np.array(d2_global_features))\n",
    "\n",
    "h5f_label=h5py.File('/home/csed/ELC_activity/output_train_svm/labels.h5','w')\n",
    "h5f_label.create_dataset('dataset_1',data=np.array(target))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "h5f_data.close()\n",
    "h5f_label.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
